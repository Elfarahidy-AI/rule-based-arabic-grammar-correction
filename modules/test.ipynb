{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_level_grammar import WordLevelGrammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "grammer = WordLevelGrammer()\n",
    "word_list = ['هذا', 'في', 'الماضي', 'كان','الطلاب', 'المميزين', 'مجتهدون', '.']\n",
    "\n",
    "print(grammer.  is_verbal_sentence(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_to_word_lists(text):\n",
    "    # Split the text by dots and strip any leading/trailing whitespace from each segment\n",
    "    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n",
    "    \n",
    "    # Split each sentence into a list of words\n",
    "    word_lists = [sentence.split() + ['.'] for sentence in sentences]  # Append a dot at the end\n",
    "    \n",
    "    return word_lists\n",
    "\n",
    "\n",
    "\n",
    "text = \"و كان الطالبين يدرسان بجد. كان المعلمان يساعدون الطلاب في الفصل.\"\n",
    "\n",
    "word_lists = split_text_to_word_lists(text)\n",
    "\n",
    "for word_list in word_lists:\n",
    "    print(grammer.is_verbal_sentence(word_list))\n",
    "    \n",
    "print(\"\")\n",
    "print(grammer.get_verbs_indeces(word_lists[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arabic_text_with_errors = \"\"\"\n",
    "كان الولدان إثنان يلعب في احمد الحديقة.\n",
    "البنت يقرأ كتابًا تحت الشجرة.\n",
    "الطالب تدرسان معًا في المكتبة.\n",
    "ذهبت الأسرة إلى سوق.\n",
    "أشتريت ثلاث كتب من المكتبة.\n",
    "الكتابة على الطاولة.\n",
    "المعلمين يعلم الطلاب في الصف.\n",
    "كان الرجال يجلسون على الكرسي.\n",
    "ألبنات تلعب في الساحتان المتجاورتان الصغيرتان.\n",
    "ألصديق يذهبان إلى المدرسة كل يوم.\n",
    "نريد أن نذهب اليكم الحديقة.\n",
    "نحب أن نقرأ الكتب.\n",
    "يجب ان نحترم الآخرين.\n",
    "عليكما ان تدرسان بجد.\n",
    "يمكنكم أن تحققون أحلامكم.\n",
    "لن نستسلم أبدا.\n",
    "علينا أن نتعاون معا.\n",
    "يجب أن نحافظ على البيئة.\n",
    "نود أن نسافر حول العالم.\n",
    "لا تنسون أن تتصلوا بي.\n",
    "لم ينجو المصاب من الحادث.\n",
    "\"\"\"\n",
    "\n",
    "# arabic_text_with_errors = \"لن انفعل اي من هذا\"\n",
    "def print_sentences(text):\n",
    "    sentences = text.split('.')\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if sentence:\n",
    "            print(sentence + '.')\n",
    "\n",
    "def split_text_to_word_lists(text):\n",
    "    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n",
    "    \n",
    "    word_lists = [sentence.split() + ['.'] for sentence in sentences]  # Append a dot at the end\n",
    "    \n",
    "    return word_lists\n",
    "\n",
    "def concatenate_words(word_lists):\n",
    "    result = \"\"\n",
    "    for word_list in word_lists:\n",
    "        for word in word_list:\n",
    "            result += word + \" \"\n",
    "    return result.strip()\n",
    "\n",
    "print(arabic_text_with_errors)\n",
    "print(split_text_to_word_lists(arabic_text_with_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "word_lists = split_text_to_word_lists(arabic_text_with_errors)\n",
    "\n",
    "print(\"\")\n",
    "new_word_lists = []\n",
    "for word_list in word_lists:\n",
    "    result = grammer.handle_word_level_errors(word_list)\n",
    "    new_word_lists.append(result)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "modified_text = concatenate_words(new_word_lists)\n",
    "print_sentences(modified_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_level_grammar import WordLevelGrammer\n",
    "\n",
    "gl = WordLevelGrammer()\n",
    "text = \"هذين المعلمين مدهشين\"\n",
    "word_list = text.split()\n",
    "print(gl.handle_word_level_errors(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_grammar import ContextGrammar\n",
    "\n",
    "cg = ContextGrammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['كان', 'هناك', 'معلمان', 'متميزان']\n",
      "['كان', 'معلما', 'المدرسة', 'متميزين']\n",
      "['كان', 'في', 'الفصل', 'معلمين', 'متميزين']\n"
     ]
    }
   ],
   "source": [
    "text1 = \"كان هناك معلمين متميزان \"\n",
    "text2 = \"كان معلمان المدرسة متميزين\"\n",
    "text3 = \"كان في الفصل معلمين متميزين\"\n",
    "\n",
    "\n",
    "words = text1.split()\n",
    "words = cg.handle_context_level_errors(words)\n",
    "print(words)\n",
    "\n",
    "\n",
    "words = text2.split()\n",
    "words = cg.handle_context_level_errors(words)\n",
    "print(words)\n",
    "\n",
    "\n",
    "\n",
    "words = text3.split()\n",
    "words = cg.handle_context_level_errors(words)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
